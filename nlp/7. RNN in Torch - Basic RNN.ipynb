{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Neuron RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Wx = torch.randn(n_inputs, n_neurons)   ## Wx : input state at T\n",
    "        self.Wy = torch.randn(n_neurons, n_neurons)  ## Wy : previous state\n",
    "        \n",
    "        self.b = torch.zeros(1, n_neurons)\n",
    "        \n",
    "    def forward(self, X0, X1):\n",
    "        self.Y0 = torch.tanh(torch.mm(X0, self.Wx) + self.b)\n",
    "        self.Y1 = torch.tanh(torch.mm(self.Y0, self.Wy) + torch.mm(X1, self.Wx) + self.b)\n",
    "        \n",
    "        return self.Y0, self.Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9845],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9919]])\n",
      "tensor([[ 1.0000],\n",
      "        [-0.8775],\n",
      "        [ 1.0000],\n",
      "        [ 0.9973]])\n"
     ]
    }
   ],
   "source": [
    "N_INPUT = 4\n",
    "N_NEURONS = 1\n",
    "\n",
    "X0_batch = torch.tensor([[0,1,2,0], [3,4,5,0], \n",
    "                         [6,7,8,0], [9,0,1,0]], dtype = torch.float) ## at time t=0\n",
    "\n",
    "X1_batch = torch.tensor([[9,8,7,0], [0,0,0,0], \n",
    "                         [6,5,4,0], [3,2,1,0]], dtype = torch.float) ## at time t=1\n",
    "\n",
    "model = SingleRNN(N_INPUT, N_NEURONS)\n",
    "\n",
    "Y0_val, Y1_val = model(X0_batch, X1_batch)\n",
    "\n",
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Neuron RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Wx = torch.randn(n_inputs, n_neurons)   ## Wx : input state at T\n",
    "        self.Wy = torch.randn(n_neurons, n_neurons)  ## Wy : previous state\n",
    "        \n",
    "        self.b = torch.zeros(1, n_neurons)\n",
    "        \n",
    "    def forward(self, X0, X1):\n",
    "        self.Y0 = torch.tanh(torch.mm(X0, self.Wx) + self.b)\n",
    "        self.Y1 = torch.tanh(torch.mm(self.Y0, self.Wy) + torch.mm(X1, self.Wx) + self.b)\n",
    "        \n",
    "        return self.Y0, self.Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1952, -0.8710,  0.9961, -0.9758,  0.9638],\n",
      "        [ 0.9818, -0.5390,  1.0000, -1.0000,  1.0000],\n",
      "        [ 0.9997,  0.1309,  1.0000, -1.0000,  1.0000],\n",
      "        [ 0.9971,  1.0000, -0.9999, -1.0000,  0.9796]])\n",
      "tensor([[ 1.0000,  1.0000,  1.0000, -1.0000,  1.0000],\n",
      "        [ 0.9600,  0.9749, -0.7540, -0.9486,  0.9965],\n",
      "        [ 1.0000,  0.9995,  0.9927, -1.0000,  1.0000],\n",
      "        [ 0.9904,  0.9610, -0.5376, -0.9999,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "N_INPUT = 3\n",
    "N_NEURONS = 5\n",
    "\n",
    "X0_batch = torch.tensor([[0,1,2], [3,4,5], \n",
    "                         [6,7,8], [9,0,1]],\n",
    "                        dtype = torch.float) #t=0 => 4 X 3\n",
    "\n",
    "X1_batch = torch.tensor([[9,8,7], [0,0,0], \n",
    "                         [6,5,4], [3,2,1]],\n",
    "                        dtype = torch.float) #t=1 => 4 X 3\n",
    "\n",
    "model = SingleRNN(N_INPUT, N_NEURONS)\n",
    "\n",
    "Y0_val, Y1_val = model(X0_batch, X1_batch)\n",
    "\n",
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out is of dim 4x5 (input size x total neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch built in RNN cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8987, -0.1500,  0.6439, -0.5638,  0.6212],\n",
      "        [ 0.9970,  0.3355,  0.6603,  0.9784, -0.3403],\n",
      "        [ 1.0000,  0.7483,  0.1395,  0.9338, -0.8079],\n",
      "        [ 0.9942,  0.9891, -0.9870,  0.9989, -0.9976]], grad_fn=<TanhBackward>)\n",
      "tensor([[ 1.0000,  0.9885, -0.4932,  0.9946, -0.8862],\n",
      "        [-0.0852, -0.1808, -0.4218,  0.4770, -0.1291],\n",
      "        [ 0.9986,  0.9488, -0.7538,  0.9801, -0.8985],\n",
      "        [ 0.7924,  0.7450, -0.7464,  0.8564, -0.4963]], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNNCell(3,5) ##Â input x dim\n",
    "\n",
    "X_batch = torch.tensor([[[0,1,2], [3,4,5], \n",
    "                         [6,7,8], [9,0,1]],\n",
    "                        [[9,8,7], [0,0,0], \n",
    "                         [6,5,4], [3,2,1]]], dtype = torch.float) # X0 and X1\n",
    "\n",
    "hx = torch.randn(4,5)\n",
    "output = []\n",
    "\n",
    "for i in range(2):\n",
    "    hx = rnn(X_batch[i], hx)\n",
    "    output.append(hx)\n",
    "    \n",
    "print(output[0])\n",
    "print(output[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic Basic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size, n_input, n_neurons):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.RNNCell(n_input, n_neurons)\n",
    "        self.hx = torch.randn(batch_size, n_neurons) ## initialize the hidden\n",
    "        \n",
    "    def forward(self, X):\n",
    "        output = []\n",
    "        \n",
    "        for i in range(2):\n",
    "            self.hx = self.rnn(X[i], self.hx)\n",
    "            output.append(self.hx)\n",
    "            \n",
    "        return output, self.hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.3527,  0.3093,  0.3270,  0.5035, -0.2668],\n",
      "        [-0.3363,  0.4618,  0.9708,  0.7014,  0.9509],\n",
      "        [-0.1413,  0.9185,  0.9998,  0.3525,  0.9999],\n",
      "        [ 0.9798,  0.0171, -0.8942, -0.9803,  0.9998]], grad_fn=<TanhBackward>), tensor([[ 0.7093,  0.6840,  0.9988,  0.2124,  1.0000],\n",
      "        [-0.0401, -0.0762, -0.8577,  0.5472, -0.8442],\n",
      "        [ 0.7284,  0.2882,  0.9030,  0.4909,  0.9981],\n",
      "        [ 0.4148, -0.7623,  0.8014, -0.6518,  0.9761]], grad_fn=<TanhBackward>)]\n",
      "\n",
      "tensor([[ 0.7093,  0.6840,  0.9988,  0.2124,  1.0000],\n",
      "        [-0.0401, -0.0762, -0.8577,  0.5472, -0.8442],\n",
      "        [ 0.7284,  0.2882,  0.9030,  0.4909,  0.9981],\n",
      "        [ 0.4148, -0.7623,  0.8014, -0.6518,  0.9761]], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "FIXED_BATCH_SIZE = 4 # our batch size is fixed for now\n",
    "N_INPUT = 3\n",
    "N_NEURONS = 5\n",
    "\n",
    "X_batch = torch.tensor([[[0,1,2], [3,4,5], \n",
    "                         [6,7,8], [9,0,1]],\n",
    "                        [[9,8,7], [0,0,0], \n",
    "                         [6,5,4], [3,2,1]]\n",
    "                       ], dtype = torch.float) # X0 and X1\n",
    "\n",
    "model = ClassicRNN(FIXED_BATCH_SIZE, N_INPUT, N_NEURONS)\n",
    "\n",
    "output_val, states_val = model(X_batch)\n",
    "\n",
    "\n",
    "print(output_val) # contains all output for all timesteps\n",
    "print()\n",
    "print(states_val) # contains values for final state or final timestep, i.e., t=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
