{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_Modelling_LDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1U9_mp7zuV6p_2yD4M8NlZzBT7qL3zU1-",
      "authorship_tag": "ABX9TyN30yl5xUu0TK+XoINIqiul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishuatgithub/MLPy/blob/master/Topic_Modelling_LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw-7mbkMg9FK",
        "colab_type": "text"
      },
      "source": [
        "# Topic Modelling using Latent-Dirichlet Allocation\n",
        "\n",
        "- Blog URL : [Topic Modelling : Latent Dirichlet Allocation, an introduction](https://anotherreeshu.wordpress.com)\n",
        "- Author   : Rishu Shrivastava"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1UbX8SHg7sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQDt-6pYwVoN",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: Loading Data\n",
        "\n",
        "As part of this step we will load the data into the dataframe\n",
        "\n",
        "- Dataset Kernel : https://www.kaggle.com/hengzheng/news-category-classifier-val-acc-0-65"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUeRe8UkhNSZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d528b53a-873c-4e3f-b976-83c11b79325b"
      },
      "source": [
        "filename = '/content/drive/My Drive/Colab Notebooks/data/news_data/News_Category_Dataset_v2.json'\n",
        "data = pd.read_json(filename, lines=True)\n",
        "data.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>headline</th>\n",
              "      <th>authors</th>\n",
              "      <th>link</th>\n",
              "      <th>short_description</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
              "      <td>Melissa Jeltsen</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
              "      <td>She left her husband. He killed their children...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
              "      <td>Andy McDonald</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
              "      <td>Of course it has a song.</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
              "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
              "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
              "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category  ...       date\n",
              "0          CRIME  ... 2018-05-26\n",
              "1  ENTERTAINMENT  ... 2018-05-26\n",
              "2  ENTERTAINMENT  ... 2018-05-26\n",
              "3  ENTERTAINMENT  ... 2018-05-26\n",
              "4  ENTERTAINMENT  ... 2018-05-26\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U8aunHEwN7y",
        "colab_type": "text"
      },
      "source": [
        "- For the purpose of this blog, we will try to only look at the description of the data and try to generate the topic using Topic Modelling (LDA)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W3lHt3-vON1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Selecting only the interested dataset - short_description\n",
        "\n",
        "df = data['short_description']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAOhGD_QwE25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b736d6e0-8d03-499d-d33e-66f4dde44579"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    She left her husband. He killed their children...\n",
              "1                             Of course it has a song.\n",
              "2    The actor and his longtime girlfriend Anna Ebe...\n",
              "3    The actor gives Dems an ass-kicking for not fi...\n",
              "4    The \"Dietland\" actress said using the bags is ...\n",
              "Name: short_description, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrNM1Y8kBhZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd99240f-c4a7-4304-da7b-3abf226e3281"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200853,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CeNOj-U5ka-",
        "colab_type": "text"
      },
      "source": [
        "### Step 2: Pre-processing data\n",
        "\n",
        "**a. Applying Count Vectorizer to pre-process the data into vectors.**\n",
        "\n",
        "In the parameters section of CountVectorizer(), we define the max_df and min_df.\n",
        "\n",
        "- max_df : Ignore the words that occurs more than 95% of the corpus. \n",
        "- min_df : Accept the words in preparation of vocab that occurs in atleast 2 of the documents in the corpus.\n",
        "- stop_words : Remove the stop words. We can do this in separate steps or in a single step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMviYF-T5QLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cv = CountVectorizer(max_df=0.95, min_df=1, stop_words='english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVNAlqdJ6or7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cv_transformed = df_cv.fit_transform(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO91FbiIA8x0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bb886a59-7bab-435f-9a6a-65966af5888f"
      },
      "source": [
        "df_cv_transformed"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<200853x73729 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1922096 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjqPYCIuB-si",
        "colab_type": "text"
      },
      "source": [
        "*Here you can notice that the transformed dataset holds a sparse matrix with a dimension of 200853x73729; where 200853 is the total number of rows and 73729 is the total word corpus.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-GkVdCHCqo-",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: Building Latent-Dirichlet Algorithm using scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h33cgl50BFgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_model = LatentDirichletAllocation(n_components=10, batch_size=128, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr_ESU3ODNaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_model.fit(df_cv_transformed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyxCeru0DTNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}