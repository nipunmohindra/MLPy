{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.\\tVa !',\n",
       " 'Run!\\tCours\\u202f!',\n",
       " 'Run!\\tCourez\\u202f!',\n",
       " 'Wow!\\tÇa alors\\u202f!',\n",
       " 'Fire!\\tAu feu !',\n",
       " \"Help!\\tÀ l'aide\\u202f!\",\n",
       " 'Jump.\\tSaute.',\n",
       " 'Stop!\\tÇa suffit\\u202f!',\n",
       " 'Stop!\\tStop\\u202f!',\n",
       " 'Stop!\\tArrête-toi !']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_FILE = '../../Data/language_data/eng-fra.txt'\n",
    "\n",
    "with open(INPUT_FILE,'r',encoding='utf-8') as f:\n",
    "    lines = f.read().strip().split('\\n')\n",
    "    \n",
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135842"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = 30000\n",
    "\n",
    "original_word_pairs = [[w for w in l.split('\\t')] for l in lines[:SAMPLE]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(original_word_pairs,columns=[\"en\",\"fr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>Au feu !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      en          fr\n",
       "0    Go.        Va !\n",
       "1   Run!     Cours !\n",
       "2   Run!    Courez !\n",
       "3   Wow!  Ça alors !\n",
       "4  Fire!    Au feu !"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    '''\n",
    "        convert unicode characters to ascii\n",
    "    '''\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!='Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    '''\n",
    "        pre-process the sentence.\n",
    "    '''\n",
    "    w = unicodeToAscii(w.lower().strip()) \n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)  ## creating a space between a word and the punctuation following it\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w) ## replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    \n",
    "    w = w.rstrip().strip()\n",
    "    \n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"en\"] = data.en.apply(lambda x: preprocess_sentence(x))\n",
    "data[\"fr\"] = data.fr.apply(lambda x: preprocess_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; go . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; va ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; cours ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; run ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; courez ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; wow ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; ca alors ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; fire ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; au feu ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;start&gt; help ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; a l aide ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;start&gt; jump . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; saute . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;start&gt; stop ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; ca suffit ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;start&gt; stop ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; stop ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;start&gt; stop ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; arrete toi ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     en                          fr\n",
       "0    <start> go . <end>          <start> va ! <end>\n",
       "1   <start> run ! <end>       <start> cours ! <end>\n",
       "2   <start> run ! <end>      <start> courez ! <end>\n",
       "3   <start> wow ! <end>    <start> ca alors ! <end>\n",
       "4  <start> fire ! <end>      <start> au feu ! <end>\n",
       "5  <start> help ! <end>    <start> a l aide ! <end>\n",
       "6  <start> jump . <end>       <start> saute . <end>\n",
       "7  <start> stop ! <end>   <start> ca suffit ! <end>\n",
       "8  <start> stop ! <end>        <start> stop ! <end>\n",
       "9  <start> stop ! <end>  <start> arrete toi ! <end>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Building vocabulary index\n",
    "\n",
    "class LangIndex():\n",
    "    def __init__(self, lang):\n",
    "        '''\n",
    "            lang are the list of phrases from each language\n",
    "        '''\n",
    "        self.lang = lang\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab = set()\n",
    "        \n",
    "        self.create_index()\n",
    "        \n",
    "    \n",
    "    def create_index(self):\n",
    "        \n",
    "        for phrase in self.lang:\n",
    "            '''update the indivisual token'''\n",
    "            self.vocab.update(phrase.split(' '))\n",
    "            \n",
    "        self.vocab = sorted(self.vocab)\n",
    "        \n",
    "        self.word2idx['<pad>'] = 0  ## padd mapping\n",
    "        \n",
    "        ## word to index mapping\n",
    "        for index, word in enumerate(self.vocab):\n",
    "            self.word2idx[word] = index + 1\n",
    "            \n",
    "        for index, word in enumerate(self.vocab):\n",
    "            self.idx2word[index] = word\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang = LangIndex(data['fr'].values.tolist())\n",
    "output_lang = LangIndex(data['en'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vectorise the input and output langs\n",
    "\n",
    "input_tensor = [[input_lang.word2idx[f] for f in fr.split(' ')] for fr in data['fr'].values.tolist()]\n",
    "output_tensor = [[output_lang.word2idx[e] for e in en.split(' ')] for en in data['en'].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 7451, 1, 4],\n",
       " [5, 1678, 1, 4],\n",
       " [5, 1670, 1, 4],\n",
       " [5, 994, 279, 1, 4],\n",
       " [5, 599, 3150, 1, 4],\n",
       " [5, 7, 4159, 181, 1, 4],\n",
       " [5, 6541, 3, 4],\n",
       " [5, 994, 6935, 1, 4],\n",
       " [5, 6901, 1, 4],\n",
       " [5, 458, 7216, 1, 4]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 1686, 3, 4],\n",
       " [5, 3279, 1, 4],\n",
       " [5, 3279, 1, 4],\n",
       " [5, 4410, 1, 4],\n",
       " [5, 1477, 1, 4],\n",
       " [5, 1850, 1, 4],\n",
       " [5, 2147, 3, 4],\n",
       " [5, 3731, 1, 4],\n",
       " [5, 3731, 1, 4],\n",
       " [5, 3731, 1, 4]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 1686, 3, 4]\n",
      "?\n",
      "goal\n",
      "<end>\n",
      "<start>\n"
     ]
    }
   ],
   "source": [
    "print(output_tensor[0])\n",
    "\n",
    "for idx in output_tensor[0]:\n",
    "    print(output_lang.idx2word[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length_input: 17 \t max_length_output: 10\n"
     ]
    }
   ],
   "source": [
    "### calculate the max length of input and output tensors\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "max_length_input, max_length_output = max_length(input_tensor), max_length(output_tensor)\n",
    "\n",
    "print(f'max_length_input: {max_length_input} \\t max_length_output: {max_length_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(x, max_len):\n",
    "    padd_seq = np.zeros((max_len), dtype=np.int64)\n",
    "    \n",
    "    if len(x) > max_len:\n",
    "        padd_seq[:] = x[:max_len]\n",
    "    else:\n",
    "        padd_seq[:len(x)] = x\n",
    "    \n",
    "    return padd_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = np.zeros((10), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad[:4] = [5, 1686, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   5, 1686,    3,    4,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add padding to the input and output tensors to make it similar\n",
    "\n",
    "input_pad_tensor = [pad_sequences(tensor, max_length_input) for tensor in input_tensor]\n",
    "output_pad_tensor = [pad_sequences(tensor, max_length_output) for tensor in output_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 1678, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "17\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(input_pad_tensor[1].tolist())\n",
    "print(len(input_pad_tensor[1]))\n",
    "print(len(output_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train: 24000  y_Train: 24000\n",
      "Length of X_test : 6000    y_test: 6000\n"
     ]
    }
   ],
   "source": [
    "### split the data into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_pad_tensor, output_pad_tensor, test_size=0.2)\n",
    "\n",
    "print(f'Length of X_train: {len(X_train)}  y_Train: {len(y_train)}')\n",
    "print(f'Length of X_test : {len(X_test)}    y_test: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create pytorch dataset\n",
    "\n",
    "class NMTDataset(Dataset):  \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.X[index]\n",
    "        y = self.y[index]\n",
    "        x_len = self.length[index]\n",
    "        \n",
    "        return x,y,x_len\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = NMTDataset(X_train, y_train)\n",
    "test_ds = NMTDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_ds = DataLoader(test_ds, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, enc_unit, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.enc_unit = enc_unit\n",
    "        self.batch_sz = batch_sz\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.enc_unit)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, lens, device):\n",
    "        ## x: batch_size, max_length\n",
    "        \n",
    "        x = self.embedding(x) ## x: batch_size, max_length, embedding_dim\n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, lens) ## unpad\n",
    "        \n",
    "        self.hidden = self.initialize_hidden_state(device)\n",
    "        \n",
    "        # output: max_length, batch_size, enc_units\n",
    "        # self.hidden: 1, batch_size, enc_units\n",
    "        output, self.hidden = self.gru(x, self.hidden)\n",
    "        output , _ = nn.utils.rnn.pad_packed_sequence(output) ## pad to the max value of output\n",
    "        \n",
    "        return output, self.hidden\n",
    "        \n",
    "    \n",
    "    def initialize_hidden_state(self, device):\n",
    "        return torch.zeros((1, self.batch_sz, self.enc_unit)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 \t 64 \t 375 \t 256\n",
      "7727 \t 4445\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(train_ds)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "EMBEDDING_DIM = 256\n",
    "UNITS = 1024\n",
    "\n",
    "vocab_inp_size = len(input_lang.word2idx)\n",
    "vocab_out_size = len(output_lang.word2idx)\n",
    "\n",
    "print(f'{BUFFER_SIZE} \\t {BATCH_SIZE} \\t {N_BATCH} \\t {EMBEDDING_DIM}')\n",
    "print(f'{vocab_inp_size} \\t {vocab_tar_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_batch(x,y, lengths):\n",
    "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
    "    x = x[indx]\n",
    "    y = y[indx]\n",
    "    return x.transpose(0,1), y, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 64, 1024])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing the encoder\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\n",
    "encoder.to(device)\n",
    "\n",
    "it = iter(train_loader)\n",
    "x1, y1, l1 = next(it)\n",
    "\n",
    "xs1, ys1, ls1 = sort_batch(x1, y1, l1)\n",
    "\n",
    "encoder_output, encoder_hidden = encoder(xs1.to(device), ls1, device)\n",
    "\n",
    "encoder_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   5, 4040,  179, 4950, 4160, 5627, 5401,    3,    4,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(train_loader)\n",
    "x1, y1, l1 = next(it)\n",
    "\n",
    "x1[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   5, 1965, 1703, 1482, 2870,    3,    4,    0,    0,    0])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 7727])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1, BATCH_SIZE, vocab_inp_size)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jalouse'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.idx2word[4040]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ibaraki'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.idx2word[1965]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
